baseURL = "https://TENGYan666.github.io/"
languageCode = "en-us"
title = "TENG Yan's Homepage"
theme = "hugo-blog-awesome"

[[menu.main]]
  name   = "Publications"
  url    = "/publications/"
  weight = 1

[Languages.en-us.params.author]
  avatar      = "avater.jpg"
  intro       = "TENG Yan"
  description    = "Shanghai Artificiall Intelligence Laboratory"  # 可以留空或删掉
  extraParagraphs = [
    "TENG Yan is currently a research scientist of Safe & Trustworhty Center at Shanghai AI Lab. She received her PhD from Delft University of Technology. Her research focuses on AI safety, value-driven design and alignment of AI, AI governance, and interdisciplinary AI research.",
    " ",
    "We have opening positions for **full-time employees, interns, joint PhDs**."
  ]


[[params.recentResearch]]
  title = "Probing the robustness of large language models safety to latent Perturbations"
  venue = "Submitted to ICLR"
  year  = 2025
  url   = "https://arxiv.org/pdf/2506.16078"

[[params.recentResearch]]
  title = "CompliAgent: Toward Agentic Safety Compliance Evaluation of Large Language Models"
  venue = "Submitted to ICLR"
  year  = 2025

[[params.recentResearch]]
  title = "GhostEI-Bench: Do Mobile Agent Withstand Environmental Injection in Dynamic On-Device Environments?"
  venue = "Submitted to ICLR"
  year  = 2025

[[params.recentResearch]]
  title = "FreezeVLA: Action-Freezing Attacks on Vision-Language-Action Models"
  venue = "Submitted to ICLR"
  year  = 2025

[[params.recentResearch]]
  title = "Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?"
  venue = "ACM MM"
  year  = 2025
  url   = "https://arxiv.org/abs/2506.14805"

[[params.recentResearch]]
  title = "LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models"
  venue = "Submittd to AAAI"
  year  = 2025
  url   = "https://arxiv.org/html/2508.12733v1"

[[params.recentResearch]]
  title = "The Other Mind: How Language Models Exhibit Human Temporal Cognition"
  venue = "Submitted to AAAI"
  year  = 2025
  url   = "https://www.arxiv.org/abs/2507.15851v1"

[[params.recentResearch]]
  title = "SafeVid: Toward Safety Aligned Video Large Multimodal Models"
  venue = "NeurIPS"
  year  = 2025
  url   = "https://arxiv.org/abs/2505.11926"

 [[params.recentResearch]]
  title = "JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models"
  venue = "NeurIPS"
  year  = 2025
  url   = "https://arxiv.org/abs/2505.19610" 

[[params.recentResearch]]
  title = "Reflection-Bench: Evaluating Epistemic Agency in Large Language Models"
  venue = "ICML"
  year  = 2025
  url   = "https://arxiv.org/pdf/2410.16270"
  
[[params.recentResearch]]
  title = "A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos"
  venue = "ACL findings"
  year  = 2025
  url   = "https://arxiv.org/abs/2502.15806"
  
[[params.recentResearch]]
  title = "From Evasion to Concealment: Stealthy Knowledge Unlearning for LLMs"
  venue = "ACL findings"
  year  = 2025
  url   = "https://arxiv.org/pdf/2410.16270"
  
[[params.recentResearch]]
  title = "Collectivism and individualism political bias in large language models: A two-step approach"
  venue = "Big Data & Society"
  year  = 2025
  url   = "https://journals.sagepub.com/doi/10.1177/20539517251343861"
  
[[params.recentResearch]]
  title = "JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models"
  venue = "Submitted to NeurIPS"
  year  = 2025
  url   = "https://arxiv.org/abs/2505.19610"

[[params.recentResearch]]
  title = "HoneypotNet: Backdoor Attacks Against Model Extraction"
  venue = "AAAI"
  year  = 2025
  url   = "https://arxiv.org/pdf/2501.01090"

[[params.recentResearch]]
  title = "StolenLoRA: Exploring LoRA Extraction Attacks via Synthetic Data"
  venue = "ICCV"
  year  = 2025

[[params.recentResearch]]
  title = "IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves"
  venue = "ICCV"
  year  = 2025
  url   = "https://arxiv.org/abs/2411.00827"

[[params.recentResearch]]
  title = "Chain of Risks Evaluation (CORE): A framework for safer large language models in public mental health"
  venue = "Psychiatry and Clinical Neurosciences"
  year  = 2025
  url   = "https://onlinelibrary.wiley.com/doi/10.1111/pcn.13781"


# contact
[[params.socialIcons]]
name = "github"
url = "https://github.com/AI45Lab"

[[params.socialIcons]]
name = "email"
url = "tengyan@pjlab.org.cn"

